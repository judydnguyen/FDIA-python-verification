{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\",None)\n",
    "pd.set_option(\"display.max_rows\",None)\n",
    "\n",
    "colors = [\n",
    "    \"#e6bf7b\", \"#c8a36c\", \"#936747\", \"#592720\", \"#dcdcdc\", \"#a9a9a9\",\n",
    "    \"#708090\", \"#696969\", \"#e3f988\", \"#b0c24a\", \"#867e36\", \"#545a2c\",\n",
    "    \"#98ff98\", \"#00a550\", \"#00703c\", \"#013220\"\n",
    "]\n",
    "sns.palplot(sns.color_palette(colors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import torch\n",
    "\n",
    "# Load and Clean Data\n",
    "df = pd.read_csv('fdia_data/data1.csv')\n",
    "\n",
    "# Change column \"marker\" to numerical value\n",
    "df['marker'] = pd.Categorical(df['marker']).codes\n",
    "\n",
    "# Data cleaning\n",
    "df = df.dropna()\n",
    "df = df.replace([float('inf'), float('-inf')], float('nan'))\n",
    "df = df.dropna()\n",
    "\n",
    "# Split the data\n",
    "X = df[df.columns.difference(['marker'])].values\n",
    "Y = df['marker'].values\n",
    "\n",
    "# Standardize the features\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "# X_transform = scaler.fit_transform(X)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test_transform = scaler.transform(X_test)\n",
    "# print(f\"X_test_transform: {X_test_transform}\")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test_transform, dtype=torch.float32)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.long)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.long)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "test_dataset = TensorDataset(X_test, Y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save data for further verification\n",
    "# import numpy as np\n",
    "\n",
    "X_test_np = X_test.numpy()\n",
    "X_test_np_transform = X_test_transform\n",
    "Y_test_np = Y_test.numpy()\n",
    "np.savez(f'np_data/test_data_01_original.npz', X=X_test_np, y=Y_test_np)\n",
    "np.savez(f'np_data/test_data_01.npz', X=X_test_np_transform, y=Y_test_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# Define FFNN Model\n",
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hiddens=[50, 100, 50]):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hiddens[0])\n",
    "        self.fc2 = nn.Linear(hiddens[0], hiddens[1])\n",
    "        self.fc3 = nn.Linear(hiddens[1], hiddens[2])\n",
    "        self.fc4 = nn.Linear(hiddens[2], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "import torch.onnx\n",
    "\n",
    "# Function to save the model as ONNX format\n",
    "def save_model_onnx(model, input_size, onnx_file_path):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Create a dummy input tensor with the correct input size (batch_size, input_size)\n",
    "    # The batch size can be arbitrary, here batch size is set to 1\n",
    "    x = torch.randn(1, input_size, requires_grad=False)\n",
    "    \n",
    "    # Export the model\n",
    "    torch_out = torch.onnx.export(model,         # Model being run\n",
    "                                   x,             # Model input (or a tuple for multiple inputs)\n",
    "                                   onnx_file_path, # Where to save the model\n",
    "                                   export_params=True,  # Store the trained parameter weights inside the model file\n",
    "                                   opset_version=9)    # The ONNX version to export the model to)\n",
    "    print('Model has been saved in ONNX format at {}'.format(onnx_file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from trades import trades_loss\n",
    "\n",
    "def adversarial_training(model, optimizer, criterion, train_loader, num_epochs, device=\"cuda\", args=None):\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # calculate robust loss - TRADES loss\n",
    "            loss = trades_loss(model=model,\n",
    "                            x_natural=data,\n",
    "                            y=target,\n",
    "                            optimizer=optimizer,\n",
    "                            step_size=args['step_size'],\n",
    "                            epsilon=args['epsilon'],\n",
    "                            perturb_steps=args['num_steps'],\n",
    "                            beta=args['beta'], \n",
    "                            distance='l_inf',\n",
    "                            criterion=criterion)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch % 20 == 0:\n",
    "            print('Epoch [{}/{}], \\t Loss: {:.4f}, \\t Train Acc: {:.4f}'.format(epoch+1, num_epochs, loss.item(), 100.0*correct/total))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:00<02:39,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], \t Loss: 0.4156, \t Train Acc: 78.2620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 21/500 [00:06<02:27,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/500], \t Loss: 0.3458, \t Train Acc: 81.4564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 41/500 [00:12<02:21,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/500], \t Loss: 0.2470, \t Train Acc: 88.7114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 61/500 [00:18<02:16,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/500], \t Loss: 0.1642, \t Train Acc: 92.1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 81/500 [00:24<02:09,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/500], \t Loss: 0.1831, \t Train Acc: 93.0157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 101/500 [00:31<02:02,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [101/500], \t Loss: 0.1710, \t Train Acc: 94.9919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 121/500 [00:37<01:57,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [121/500], \t Loss: 0.1463, \t Train Acc: 94.9919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 141/500 [00:43<01:51,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [141/500], \t Loss: 0.1826, \t Train Acc: 94.8295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 161/500 [00:49<01:45,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [161/500], \t Loss: 0.1154, \t Train Acc: 95.5874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 181/500 [00:55<01:38,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [181/500], \t Loss: 0.1090, \t Train Acc: 95.9394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 201/500 [01:01<01:32,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [201/500], \t Loss: 0.1491, \t Train Acc: 96.2101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 221/500 [01:08<01:26,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [221/500], \t Loss: 0.0959, \t Train Acc: 96.2101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 241/500 [01:14<01:21,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [241/500], \t Loss: 0.0809, \t Train Acc: 96.1289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 261/500 [01:20<01:14,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [261/500], \t Loss: 0.1441, \t Train Acc: 96.2642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 281/500 [01:26<01:08,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [281/500], \t Loss: 0.0862, \t Train Acc: 96.5349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 301/500 [01:32<01:01,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [301/500], \t Loss: 0.1094, \t Train Acc: 96.9681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 321/500 [01:39<00:54,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [321/500], \t Loss: 0.1231, \t Train Acc: 96.9410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 341/500 [01:45<00:48,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [341/500], \t Loss: 0.1191, \t Train Acc: 97.1305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 361/500 [01:51<00:42,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [361/500], \t Loss: 0.0993, \t Train Acc: 96.3996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 381/500 [01:57<00:36,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [381/500], \t Loss: 0.0801, \t Train Acc: 97.1305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 401/500 [02:03<00:30,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [401/500], \t Loss: 0.0667, \t Train Acc: 97.3470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 421/500 [02:09<00:24,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [421/500], \t Loss: 0.0532, \t Train Acc: 96.9681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 441/500 [02:16<00:18,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [441/500], \t Loss: 0.1437, \t Train Acc: 96.7786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 461/500 [02:22<00:12,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [461/500], \t Loss: 0.2183, \t Train Acc: 96.8056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 481/500 [02:28<00:05,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [481/500], \t Loss: 0.0550, \t Train Acc: 97.5907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:34<00:00,  3.24it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# hiddens = [100, 200, 100] #lr 0.0002\n",
    "hiddens = [50, 100, 50]\n",
    "# hiddens = [200, 400, 200]\n",
    "model = FFNN(input_size=X.shape[1], output_size=2, hiddens=hiddens)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "num_epochs = 500\n",
    "args = {\n",
    "    'step_size': 0.01,\n",
    "    'epsilon': 0.05,\n",
    "    'num_steps': 1,\n",
    "    'beta': 1\n",
    "}\n",
    "model.to(\"cuda\")\n",
    "adversarial_training(model, optimizer, criterion, train_loader, num_epochs, \n",
    "                     device=\"cuda\", args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m      5\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m), labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m     total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/judy/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m, in \u001b[0;36mFFNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 13\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[1;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x))\n",
      "File \u001b[0;32m~/miniconda3/envs/judy/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/judy/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print('Test Accuracy of the model on the test dataset: {} %'.format(accuracy))\n",
    "\n",
    "model_path = f'onnx_models/fdia_model_ffnn_pytorch_{hiddens[0]}_{hiddens[1]}_{hiddens[2]}'\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), f'{model_path}_torch.pth')\n",
    "\n",
    "# Save the model\n",
    "input_size = X.shape[1]\n",
    "onnx_file_path = f'{model_path}.onnx'\n",
    "model.to(\"cpu\")\n",
    "save_model_onnx(model, input_size, onnx_file_path)\n",
    "\n",
    "print(\"Model saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "judy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
