{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option(\"display.max_columns\",None)\n",
    "pd.set_option(\"display.max_rows\",None)\n",
    "\n",
    "colors = [\n",
    "    \"#e6bf7b\", \"#c8a36c\", \"#936747\", \"#592720\", \"#dcdcdc\", \"#a9a9a9\",\n",
    "    \"#708090\", \"#696969\", \"#e3f988\", \"#b0c24a\", \"#867e36\", \"#545a2c\",\n",
    "    \"#98ff98\", \"#00a550\", \"#00703c\", \"#013220\"\n",
    "]\n",
    "sns.palplot(sns.color_palette(colors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import torch\n",
    "\n",
    "# Load and Clean Data\n",
    "df = pd.read_csv('fdia_data/data1.csv')\n",
    "\n",
    "# Change column \"marker\" to numerical value\n",
    "df['marker'] = pd.Categorical(df['marker']).codes\n",
    "\n",
    "# Data cleaning\n",
    "df = df.dropna()\n",
    "df = df.replace([float('inf'), float('-inf')], float('nan'))\n",
    "df = df.dropna()\n",
    "\n",
    "# Split the data\n",
    "X = df[df.columns.difference(['marker'])].values\n",
    "Y = df['marker'].values\n",
    "\n",
    "# Standardize the features\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "# X_transform = scaler.fit_transform(X)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test_transform = scaler.transform(X_test)\n",
    "# print(f\"X_test_transform: {X_test_transform}\")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test_transform, dtype=torch.float32)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.long)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.long)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "test_dataset = TensorDataset(X_test, Y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save data for further verification\n",
    "# import numpy as np\n",
    "\n",
    "X_test_np = X_test.numpy()\n",
    "X_test_np_transform = X_test_transform\n",
    "Y_test_np = Y_test.numpy()\n",
    "np.savez(f'np_data/test_data_01_original.npz', X=X_test_np, y=Y_test_np)\n",
    "np.savez(f'np_data/test_data_01.npz', X=X_test_np_transform, y=Y_test_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# Define FFNN Model\n",
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hiddens=[50, 100, 50]):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hiddens[0])\n",
    "        self.fc2 = nn.Linear(hiddens[0], hiddens[1])\n",
    "        self.fc3 = nn.Linear(hiddens[1], hiddens[2])\n",
    "        self.fc4 = nn.Linear(hiddens[2], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "import torch.onnx\n",
    "\n",
    "# Function to save the model as ONNX format\n",
    "def save_model_onnx(model, input_size, onnx_file_path):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Create a dummy input tensor with the correct input size (batch_size, input_size)\n",
    "    # The batch size can be arbitrary, here batch size is set to 1\n",
    "    x = torch.randn(1, input_size, requires_grad=False)\n",
    "    \n",
    "    # Export the model\n",
    "    torch_out = torch.onnx.export(model,         # Model being run\n",
    "                                   x,             # Model input (or a tuple for multiple inputs)\n",
    "                                   onnx_file_path, # Where to save the model\n",
    "                                   export_params=True,  # Store the trained parameter weights inside the model file\n",
    "                                   opset_version=9)    # The ONNX version to export the model to)\n",
    "    print('Model has been saved in ONNX format at {}'.format(onnx_file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from trades import trades_loss\n",
    "\n",
    "def adversarial_training(model, optimizer, criterion, train_loader, num_epochs, device=\"cuda\", args=None):\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # calculate robust loss - TRADES loss\n",
    "            loss = trades_loss(model=model,\n",
    "                            x_natural=data,\n",
    "                            y=target,\n",
    "                            optimizer=optimizer,\n",
    "                            step_size=args['step_size'],\n",
    "                            epsilon=args['epsilon'],\n",
    "                            perturb_steps=args['num_steps'],\n",
    "                            beta=args['beta'], \n",
    "                            distance='l_inf',\n",
    "                            criterion=criterion)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch % 20 == 0:\n",
    "            print('Epoch [{}/{}], \\t Loss: {:.4f}, \\t Train Acc: {:.4f}'.format(epoch+1, num_epochs, loss.item(), 100.0*correct/total))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300 [00:00<02:04,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], \t Loss: 0.5516, \t Train Acc: 77.6665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 21/300 [00:07<01:41,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/300], \t Loss: 0.3311, \t Train Acc: 82.4851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 41/300 [00:15<01:35,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/300], \t Loss: 0.2995, \t Train Acc: 88.5219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 61/300 [00:22<01:27,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/300], \t Loss: 0.2473, \t Train Acc: 90.7688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 81/300 [00:29<01:16,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/300], \t Loss: 0.1438, \t Train Acc: 91.2832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 101/300 [00:36<01:09,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [101/300], \t Loss: 0.2246, \t Train Acc: 93.0157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 121/300 [00:43<01:02,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [121/300], \t Loss: 0.1991, \t Train Acc: 93.2052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 141/300 [00:50<00:55,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [141/300], \t Loss: 0.1501, \t Train Acc: 93.6925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 161/300 [00:57<00:50,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [161/300], \t Loss: 0.1779, \t Train Acc: 93.9903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 181/300 [01:04<00:43,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [181/300], \t Loss: 0.1994, \t Train Acc: 93.8549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 201/300 [01:12<00:35,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [201/300], \t Loss: 0.2435, \t Train Acc: 94.1527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 221/300 [01:19<00:27,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [221/300], \t Loss: 0.1616, \t Train Acc: 94.5046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 241/300 [01:26<00:20,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [241/300], \t Loss: 0.1902, \t Train Acc: 94.7482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 261/300 [01:33<00:13,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [261/300], \t Loss: 0.1454, \t Train Acc: 95.1814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 281/300 [01:40<00:06,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [281/300], \t Loss: 0.1892, \t Train Acc: 94.7212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:47<00:00,  2.79it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hiddens = [100, 200, 100] #lr 0.0002\n",
    "# hiddens = [200, 400, 200]\n",
    "model = FFNN(input_size=X.shape[1], output_size=2, hiddens=hiddens)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 300\n",
    "args = {\n",
    "    'step_size': 0.01,\n",
    "    'epsilon': 0.05,\n",
    "    'num_steps': 2,\n",
    "    'beta': 2\n",
    "}\n",
    "model.to(\"cuda\")\n",
    "adversarial_training(model, optimizer, criterion, train_loader, num_epochs, \n",
    "                     device=\"cuda\", args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test dataset: 0.9285714285714286 %\n",
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "Model has been saved in ONNX format at onnx_models/fdia_model_ffnn_pytorch_100_200_100.onnx\n",
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print('Test Accuracy of the model on the test dataset: {} %'.format(accuracy))\n",
    "\n",
    "model_path = f'onnx_models/fdia_model_ffnn_pytorch_{hiddens[0]}_{hiddens[1]}_{hiddens[2]}'\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), f'{model_path}_torch.pth')\n",
    "\n",
    "# Save the model\n",
    "input_size = X.shape[1]\n",
    "onnx_file_path = f'{model_path}.onnx'\n",
    "model.to(\"cpu\")\n",
    "save_model_onnx(model, input_size, onnx_file_path)\n",
    "\n",
    "print(\"Model saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "judy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
